{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StellaIbeh/Diabetes_Prediction_Mode-/blob/main/Adaobi_Stella_Ibeh_Summative_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tA-92DyWQNzH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhWF8XCGnstH"
      },
      "source": [
        "Summative Assignment_ Diabetes Prediction Model\n",
        "\n",
        "\n",
        "\n",
        "This project aims to explore the implementation of Machine Learning Models with regularization, optimization, and Error analysis techniques used in machine learning to improve models' performance, convergence speed, and efficiency for the predicction of heart diseases.\n",
        "Some of the concepts to be covered here are:\n",
        "\n",
        "Data Exploration and Reprocessing\n",
        "Data cleaning, handling, and preprocessing\n",
        "Standarization\n",
        "Spliting\n",
        "vanilla Model\n",
        "Error analysis on Vanilla Model\n",
        "Evaluation of vanilla model\n",
        "Optimized model(with atleast 3 optimization techniques)\n",
        "Error Analysis on Optimized Model\n",
        "Evaluation of optimized Model\n",
        "Summarry and discussions of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_Vg_uJcQfXb",
        "outputId": "271389ec-a31b-40a3-be57-a72b0dfb0747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "#Necessary Installation\n",
        "!pip install tensorflow\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1QlKCLFQQa2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ub5lyNvrRCU-"
      },
      "outputs": [],
      "source": [
        "# Necessary Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOtBKmaBSJfO"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3mUfwDyShK0"
      },
      "outputs": [],
      "source": [
        "drive.mount ('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "557eQZCrVqIV"
      },
      "source": [
        "Data Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpAnaHEDV1WU"
      },
      "outputs": [],
      "source": [
        "#load Dataset From Drive\n",
        "data=pd.read_csv('/content/drive/MyDrive/summative_diabetes/diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jO81WDCVGBR"
      },
      "outputs": [],
      "source": [
        "#Print the first 10 rows of the data\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbAmI4n2XV4F"
      },
      "outputs": [],
      "source": [
        "#describe data\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg8kiTcE1XTW"
      },
      "outputs": [],
      "source": [
        "#Check for missing values\n",
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIzwZ618XhbI"
      },
      "outputs": [],
      "source": [
        "#Check the shape of the data\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPdoz1F_Xlcj"
      },
      "outputs": [],
      "source": [
        "# check the correlation\n",
        "data.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl4c-FCnZOXf"
      },
      "outputs": [],
      "source": [
        "#plot Correlation Heatmap for data set\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap for Diabetes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQfI9inGa_So"
      },
      "outputs": [],
      "source": [
        "# plot for outliers\n",
        "plt.figure(figsize=(10,12))\n",
        "sns.boxplot(data=data)\n",
        "plt.title('Boxplot for Diabetes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNNInDhBZ6GC"
      },
      "source": [
        "Data Handling and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCdGqHUIaKPM"
      },
      "outputs": [],
      "source": [
        "X= data.drop('Outcome', axis=1)\n",
        "y= data['Outcome']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "#Standardize data\n",
        "scaler=MinMaxScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUCS_kYnoxyJ"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLm5BUUa9Fly"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss6ljkGh9q49"
      },
      "source": [
        "Train a Simple ML Model without an Optimization Techniques- Vanilla Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UCgMGu6W-9MG",
        "outputId": "3dc9e046-3515-4fb1-9b09-a94f1e98a135"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m576\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,745</span> (14.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,745\u001b[0m (14.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,745</span> (14.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,745\u001b[0m (14.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6484 - loss: 0.6753 - val_accuracy: 0.6429 - val_loss: 0.6721\n",
            "Epoch 2/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6546 - loss: 0.6697 - val_accuracy: 0.6429 - val_loss: 0.6688\n",
            "Epoch 3/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6650 - loss: 0.6621 - val_accuracy: 0.6429 - val_loss: 0.6670\n",
            "Epoch 4/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6316 - loss: 0.6732 - val_accuracy: 0.6429 - val_loss: 0.6649\n",
            "Epoch 5/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6540 - loss: 0.6619 - val_accuracy: 0.6429 - val_loss: 0.6633\n",
            "Epoch 6/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: 0.6675 - val_accuracy: 0.6429 - val_loss: 0.6620\n",
            "Epoch 7/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6717 - loss: 0.6484 - val_accuracy: 0.6429 - val_loss: 0.6607\n",
            "Epoch 8/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6550 - loss: 0.6550 - val_accuracy: 0.6429 - val_loss: 0.6598\n",
            "Epoch 9/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6529 - loss: 0.6551 - val_accuracy: 0.6429 - val_loss: 0.6590\n",
            "Epoch 10/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6493 - loss: 0.6562 - val_accuracy: 0.6429 - val_loss: 0.6582\n",
            "Epoch 11/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6576 - loss: 0.6518 - val_accuracy: 0.6429 - val_loss: 0.6575\n",
            "Epoch 12/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6608 - loss: 0.6492 - val_accuracy: 0.6429 - val_loss: 0.6568\n",
            "Epoch 13/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6557 - loss: 0.6496 - val_accuracy: 0.6429 - val_loss: 0.6561\n",
            "Epoch 14/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6607 - loss: 0.6469 - val_accuracy: 0.6429 - val_loss: 0.6557\n",
            "Epoch 15/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6641 - loss: 0.6449 - val_accuracy: 0.6429 - val_loss: 0.6549\n",
            "Epoch 16/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6664 - loss: 0.6423 - val_accuracy: 0.6429 - val_loss: 0.6545\n",
            "Epoch 17/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6745 - loss: 0.6362 - val_accuracy: 0.6429 - val_loss: 0.6539\n",
            "Epoch 18/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6694 - loss: 0.6382 - val_accuracy: 0.6429 - val_loss: 0.6531\n",
            "Epoch 19/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6694 - loss: 0.6365 - val_accuracy: 0.6429 - val_loss: 0.6521\n",
            "Epoch 20/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6235 - loss: 0.6630 - val_accuracy: 0.6429 - val_loss: 0.6515\n",
            "Epoch 21/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6517 - loss: 0.6449 - val_accuracy: 0.6429 - val_loss: 0.6507\n",
            "Epoch 22/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6868 - loss: 0.6261 - val_accuracy: 0.6429 - val_loss: 0.6499\n",
            "Epoch 23/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6672 - loss: 0.6370 - val_accuracy: 0.6429 - val_loss: 0.6491\n",
            "Epoch 24/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6609 - loss: 0.6395 - val_accuracy: 0.6429 - val_loss: 0.6485\n",
            "Epoch 25/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6809 - loss: 0.6274 - val_accuracy: 0.6429 - val_loss: 0.6479\n",
            "Epoch 26/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6510 - loss: 0.6434 - val_accuracy: 0.6429 - val_loss: 0.6472\n",
            "Epoch 27/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6508 - loss: 0.6431 - val_accuracy: 0.6429 - val_loss: 0.6463\n",
            "Epoch 28/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6738 - loss: 0.6266 - val_accuracy: 0.6429 - val_loss: 0.6457\n",
            "Epoch 29/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6628 - loss: 0.6338 - val_accuracy: 0.6429 - val_loss: 0.6448\n",
            "Epoch 30/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6536 - loss: 0.6396 - val_accuracy: 0.6429 - val_loss: 0.6441\n",
            "Epoch 31/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6622 - loss: 0.6329 - val_accuracy: 0.6429 - val_loss: 0.6434\n",
            "Epoch 32/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6460 - loss: 0.6394 - val_accuracy: 0.6429 - val_loss: 0.6427\n",
            "Epoch 33/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6578 - loss: 0.6340 - val_accuracy: 0.6429 - val_loss: 0.6421\n",
            "Epoch 34/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6484 - loss: 0.6382 - val_accuracy: 0.6429 - val_loss: 0.6413\n",
            "Epoch 35/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6631 - loss: 0.6294 - val_accuracy: 0.6429 - val_loss: 0.6407\n",
            "Epoch 36/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6456 - loss: 0.6385 - val_accuracy: 0.6429 - val_loss: 0.6400\n",
            "Epoch 37/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6625 - loss: 0.6291 - val_accuracy: 0.6429 - val_loss: 0.6392\n",
            "Epoch 38/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6398 - loss: 0.6374 - val_accuracy: 0.6429 - val_loss: 0.6386\n",
            "Epoch 39/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6766 - loss: 0.6179 - val_accuracy: 0.6429 - val_loss: 0.6375\n",
            "Epoch 40/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6336 - loss: 0.6419 - val_accuracy: 0.6429 - val_loss: 0.6367\n",
            "Epoch 41/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6611 - loss: 0.6239 - val_accuracy: 0.6429 - val_loss: 0.6359\n",
            "Epoch 42/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6638 - loss: 0.6256 - val_accuracy: 0.6429 - val_loss: 0.6350\n",
            "Epoch 43/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6420 - loss: 0.6355 - val_accuracy: 0.6429 - val_loss: 0.6341\n",
            "Epoch 44/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6461 - loss: 0.6312 - val_accuracy: 0.6429 - val_loss: 0.6332\n",
            "Epoch 45/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6657 - loss: 0.6218 - val_accuracy: 0.6429 - val_loss: 0.6324\n",
            "Epoch 46/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6638 - loss: 0.6192 - val_accuracy: 0.6429 - val_loss: 0.6314\n",
            "Epoch 47/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6699 - loss: 0.6139 - val_accuracy: 0.6429 - val_loss: 0.6304\n",
            "Epoch 48/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6496 - loss: 0.6256 - val_accuracy: 0.6429 - val_loss: 0.6295\n",
            "Epoch 49/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6486 - loss: 0.6249 - val_accuracy: 0.6429 - val_loss: 0.6285\n",
            "Epoch 50/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6556 - loss: 0.6185 - val_accuracy: 0.6429 - val_loss: 0.6273\n",
            "Epoch 51/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6535 - loss: 0.6203 - val_accuracy: 0.6429 - val_loss: 0.6264\n",
            "Epoch 52/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6400 - loss: 0.6271 - val_accuracy: 0.6429 - val_loss: 0.6253\n",
            "Epoch 53/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6562 - loss: 0.6177 - val_accuracy: 0.6429 - val_loss: 0.6242\n",
            "Epoch 54/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6560 - loss: 0.6135 - val_accuracy: 0.6429 - val_loss: 0.6230\n",
            "Epoch 55/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6924 - loss: 0.5945 - val_accuracy: 0.6429 - val_loss: 0.6220\n",
            "Epoch 56/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6797 - loss: 0.5982 - val_accuracy: 0.6429 - val_loss: 0.6210\n",
            "Epoch 57/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6731 - loss: 0.6046 - val_accuracy: 0.6429 - val_loss: 0.6200\n",
            "Epoch 58/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6419 - loss: 0.6166 - val_accuracy: 0.6429 - val_loss: 0.6190\n",
            "Epoch 59/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6873 - loss: 0.5897 - val_accuracy: 0.6429 - val_loss: 0.6171\n",
            "Epoch 60/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6065 - loss: 0.6289 - val_accuracy: 0.6429 - val_loss: 0.6161\n",
            "Epoch 61/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6606 - loss: 0.6063 - val_accuracy: 0.6429 - val_loss: 0.6148\n",
            "Epoch 62/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6478 - loss: 0.6094 - val_accuracy: 0.6429 - val_loss: 0.6132\n",
            "Epoch 63/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6509 - loss: 0.6085 - val_accuracy: 0.6429 - val_loss: 0.6120\n",
            "Epoch 64/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6601 - loss: 0.6070 - val_accuracy: 0.6429 - val_loss: 0.6100\n",
            "Epoch 65/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6436 - loss: 0.6103 - val_accuracy: 0.6494 - val_loss: 0.6085\n",
            "Epoch 66/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6404 - loss: 0.6126 - val_accuracy: 0.6494 - val_loss: 0.6076\n",
            "Epoch 67/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6905 - loss: 0.5788 - val_accuracy: 0.6494 - val_loss: 0.6055\n",
            "Epoch 68/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6849 - loss: 0.5916 - val_accuracy: 0.6494 - val_loss: 0.6046\n",
            "Epoch 69/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6559 - loss: 0.6051 - val_accuracy: 0.6494 - val_loss: 0.6037\n",
            "Epoch 70/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6692 - loss: 0.5919 - val_accuracy: 0.6494 - val_loss: 0.6019\n",
            "Epoch 71/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6754 - loss: 0.5917 - val_accuracy: 0.6494 - val_loss: 0.5996\n",
            "Epoch 72/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6646 - loss: 0.5907 - val_accuracy: 0.6623 - val_loss: 0.5978\n",
            "Epoch 73/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: 0.5748 - val_accuracy: 0.6558 - val_loss: 0.5968\n",
            "Epoch 74/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6624 - loss: 0.5917 - val_accuracy: 0.6558 - val_loss: 0.5945\n",
            "Epoch 75/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6993 - loss: 0.5692 - val_accuracy: 0.6494 - val_loss: 0.5937\n",
            "Epoch 76/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6940 - loss: 0.5794 - val_accuracy: 0.6558 - val_loss: 0.5913\n",
            "Epoch 77/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6570 - loss: 0.6029 - val_accuracy: 0.6623 - val_loss: 0.5903\n",
            "Epoch 78/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7109 - loss: 0.5655 - val_accuracy: 0.6623 - val_loss: 0.5889\n",
            "Epoch 79/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7064 - loss: 0.5720 - val_accuracy: 0.6558 - val_loss: 0.5883\n",
            "Epoch 80/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 0.5788 - val_accuracy: 0.6558 - val_loss: 0.5849\n",
            "Epoch 81/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.5563 - val_accuracy: 0.6948 - val_loss: 0.5831\n",
            "Epoch 82/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7266 - loss: 0.5544 - val_accuracy: 0.6948 - val_loss: 0.5815\n",
            "Epoch 83/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7014 - loss: 0.5721 - val_accuracy: 0.7078 - val_loss: 0.5799\n",
            "Epoch 84/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6914 - loss: 0.5750 - val_accuracy: 0.6883 - val_loss: 0.5788\n",
            "Epoch 85/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7202 - loss: 0.5643 - val_accuracy: 0.6948 - val_loss: 0.5767\n",
            "Epoch 86/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7034 - loss: 0.5589 - val_accuracy: 0.6883 - val_loss: 0.5751\n",
            "Epoch 87/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7047 - loss: 0.5707 - val_accuracy: 0.6948 - val_loss: 0.5738\n",
            "Epoch 88/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7192 - loss: 0.5667 - val_accuracy: 0.6948 - val_loss: 0.5723\n",
            "Epoch 89/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6993 - loss: 0.5720 - val_accuracy: 0.6818 - val_loss: 0.5715\n",
            "Epoch 90/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7103 - loss: 0.5514 - val_accuracy: 0.7078 - val_loss: 0.5691\n",
            "Epoch 91/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7154 - loss: 0.5540 - val_accuracy: 0.7143 - val_loss: 0.5679\n",
            "Epoch 92/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7193 - loss: 0.5442 - val_accuracy: 0.7078 - val_loss: 0.5668\n",
            "Epoch 93/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7131 - loss: 0.5477 - val_accuracy: 0.7013 - val_loss: 0.5649\n",
            "Epoch 94/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 0.5399 - val_accuracy: 0.7013 - val_loss: 0.5638\n",
            "Epoch 95/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.5371 - val_accuracy: 0.7078 - val_loss: 0.5623\n",
            "Epoch 96/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7200 - loss: 0.5438 - val_accuracy: 0.7078 - val_loss: 0.5611\n",
            "Epoch 97/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7171 - loss: 0.5430 - val_accuracy: 0.7013 - val_loss: 0.5615\n",
            "Epoch 98/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7068 - loss: 0.5444 - val_accuracy: 0.7013 - val_loss: 0.5590\n",
            "Epoch 99/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7024 - loss: 0.5475 - val_accuracy: 0.7143 - val_loss: 0.5578\n",
            "Epoch 100/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7032 - loss: 0.5379 - val_accuracy: 0.7078 - val_loss: 0.5556\n",
            "Epoch 101/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7018 - loss: 0.5459 - val_accuracy: 0.7273 - val_loss: 0.5542\n",
            "Epoch 102/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7152 - loss: 0.5358 - val_accuracy: 0.7208 - val_loss: 0.5529\n",
            "Epoch 103/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7128 - loss: 0.5391 - val_accuracy: 0.7143 - val_loss: 0.5533\n",
            "Epoch 104/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6952 - loss: 0.5487 - val_accuracy: 0.7143 - val_loss: 0.5506\n",
            "Epoch 105/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7220 - loss: 0.5275 - val_accuracy: 0.7143 - val_loss: 0.5492\n",
            "Epoch 106/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.5449 - val_accuracy: 0.7338 - val_loss: 0.5477\n",
            "Epoch 107/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7317 - loss: 0.5092 - val_accuracy: 0.7208 - val_loss: 0.5464\n",
            "Epoch 108/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.5469 - val_accuracy: 0.7273 - val_loss: 0.5462\n",
            "Epoch 109/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.5183 - val_accuracy: 0.7273 - val_loss: 0.5444\n",
            "Epoch 110/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5185 - val_accuracy: 0.7273 - val_loss: 0.5437\n",
            "Epoch 111/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7580 - loss: 0.4970 - val_accuracy: 0.7143 - val_loss: 0.5447\n",
            "Epoch 112/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7154 - loss: 0.5171 - val_accuracy: 0.7208 - val_loss: 0.5429\n",
            "Epoch 113/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7216 - loss: 0.5209 - val_accuracy: 0.7208 - val_loss: 0.5406\n",
            "Epoch 114/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7422 - loss: 0.5055 - val_accuracy: 0.7273 - val_loss: 0.5398\n",
            "Epoch 115/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7295 - loss: 0.5211 - val_accuracy: 0.7208 - val_loss: 0.5379\n",
            "Epoch 116/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7070 - loss: 0.5326 - val_accuracy: 0.7143 - val_loss: 0.5374\n",
            "Epoch 117/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7361 - loss: 0.5099 - val_accuracy: 0.7208 - val_loss: 0.5363\n",
            "Epoch 118/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7454 - loss: 0.5101 - val_accuracy: 0.7273 - val_loss: 0.5363\n",
            "Epoch 119/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7266 - loss: 0.5095 - val_accuracy: 0.7078 - val_loss: 0.5349\n",
            "Epoch 120/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7529 - loss: 0.5136 - val_accuracy: 0.7208 - val_loss: 0.5356\n",
            "Epoch 121/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7227 - loss: 0.5198 - val_accuracy: 0.7208 - val_loss: 0.5333\n",
            "Epoch 122/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7355 - loss: 0.5056 - val_accuracy: 0.7143 - val_loss: 0.5330\n",
            "Epoch 123/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7378 - loss: 0.5041 - val_accuracy: 0.7143 - val_loss: 0.5332\n",
            "Epoch 124/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7111 - loss: 0.5177 - val_accuracy: 0.7143 - val_loss: 0.5325\n",
            "Epoch 125/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7386 - loss: 0.4940 - val_accuracy: 0.7143 - val_loss: 0.5316\n",
            "Epoch 126/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7489 - loss: 0.5017 - val_accuracy: 0.7273 - val_loss: 0.5302\n",
            "Epoch 127/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7242 - loss: 0.5112 - val_accuracy: 0.7208 - val_loss: 0.5300\n",
            "Epoch 128/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7521 - loss: 0.4926 - val_accuracy: 0.7273 - val_loss: 0.5319\n",
            "Epoch 129/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7616 - loss: 0.4696 - val_accuracy: 0.7273 - val_loss: 0.5283\n",
            "Epoch 130/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7273 - loss: 0.5002 - val_accuracy: 0.7273 - val_loss: 0.5278\n",
            "Epoch 131/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7483 - loss: 0.4970 - val_accuracy: 0.7273 - val_loss: 0.5285\n",
            "Epoch 132/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7265 - loss: 0.5111 - val_accuracy: 0.7338 - val_loss: 0.5273\n",
            "Epoch 133/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7585 - loss: 0.4848 - val_accuracy: 0.7338 - val_loss: 0.5262\n",
            "Epoch 134/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7346 - loss: 0.4865 - val_accuracy: 0.7273 - val_loss: 0.5246\n",
            "Epoch 135/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7260 - loss: 0.5076 - val_accuracy: 0.7273 - val_loss: 0.5234\n",
            "Epoch 136/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7472 - loss: 0.4856 - val_accuracy: 0.7338 - val_loss: 0.5240\n",
            "Epoch 137/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7152 - loss: 0.5168 - val_accuracy: 0.7338 - val_loss: 0.5257\n",
            "Epoch 138/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7654 - loss: 0.4666 - val_accuracy: 0.7208 - val_loss: 0.5222\n",
            "Epoch 139/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7257 - loss: 0.5046 - val_accuracy: 0.7208 - val_loss: 0.5215\n",
            "Epoch 140/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7659 - loss: 0.4810 - val_accuracy: 0.7338 - val_loss: 0.5234\n",
            "Epoch 141/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 0.4879 - val_accuracy: 0.7338 - val_loss: 0.5207\n",
            "Epoch 142/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.4676 - val_accuracy: 0.7273 - val_loss: 0.5232\n",
            "Epoch 143/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7496 - loss: 0.4897 - val_accuracy: 0.7273 - val_loss: 0.5297\n",
            "Epoch 144/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7440 - loss: 0.5065 - val_accuracy: 0.7273 - val_loss: 0.5203\n",
            "Epoch 145/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.4939 - val_accuracy: 0.7273 - val_loss: 0.5203\n",
            "Epoch 146/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.4774 - val_accuracy: 0.7403 - val_loss: 0.5204\n",
            "Epoch 147/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7563 - loss: 0.4827 - val_accuracy: 0.7338 - val_loss: 0.5186\n",
            "Epoch 148/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.4780 - val_accuracy: 0.7403 - val_loss: 0.5190\n",
            "Epoch 149/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7250 - loss: 0.5073 - val_accuracy: 0.7403 - val_loss: 0.5183\n",
            "Epoch 150/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7422 - loss: 0.4997 - val_accuracy: 0.7338 - val_loss: 0.5178\n",
            "Epoch 151/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7708 - loss: 0.4707 - val_accuracy: 0.7273 - val_loss: 0.5221\n",
            "Epoch 152/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7525 - loss: 0.4758 - val_accuracy: 0.7403 - val_loss: 0.5180\n",
            "Epoch 153/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7636 - loss: 0.4860 - val_accuracy: 0.7403 - val_loss: 0.5208\n",
            "Epoch 154/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7717 - loss: 0.4820 - val_accuracy: 0.7403 - val_loss: 0.5174\n",
            "Epoch 155/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7591 - loss: 0.4779 - val_accuracy: 0.7273 - val_loss: 0.5210\n",
            "Epoch 156/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.4437 - val_accuracy: 0.7208 - val_loss: 0.5206\n",
            "Epoch 157/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.4511 - val_accuracy: 0.7468 - val_loss: 0.5177\n",
            "Epoch 158/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7453 - loss: 0.4913 - val_accuracy: 0.7403 - val_loss: 0.5157\n",
            "Epoch 159/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7868 - loss: 0.4688 - val_accuracy: 0.7468 - val_loss: 0.5159\n",
            "Epoch 160/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7750 - loss: 0.4832 - val_accuracy: 0.7468 - val_loss: 0.5165\n",
            "Epoch 161/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7670 - loss: 0.4720 - val_accuracy: 0.7468 - val_loss: 0.5145\n",
            "Epoch 162/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.4913 - val_accuracy: 0.7403 - val_loss: 0.5150\n",
            "Epoch 163/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7570 - loss: 0.4859 - val_accuracy: 0.7468 - val_loss: 0.5148\n",
            "Epoch 164/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7455 - loss: 0.4980 - val_accuracy: 0.7468 - val_loss: 0.5139\n",
            "Epoch 165/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 0.4630 - val_accuracy: 0.7532 - val_loss: 0.5143\n",
            "Epoch 166/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.4470 - val_accuracy: 0.7597 - val_loss: 0.5147\n",
            "Epoch 167/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 0.4685 - val_accuracy: 0.7468 - val_loss: 0.5128\n",
            "Epoch 168/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7616 - loss: 0.4853 - val_accuracy: 0.7532 - val_loss: 0.5167\n",
            "Epoch 169/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 0.5009 - val_accuracy: 0.7468 - val_loss: 0.5131\n",
            "Epoch 170/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.4655 - val_accuracy: 0.7468 - val_loss: 0.5132\n",
            "Epoch 171/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7794 - loss: 0.4642 - val_accuracy: 0.7403 - val_loss: 0.5136\n",
            "Epoch 172/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7907 - loss: 0.4461 - val_accuracy: 0.7273 - val_loss: 0.5155\n",
            "Epoch 173/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7482 - loss: 0.4741 - val_accuracy: 0.7273 - val_loss: 0.5150\n",
            "Epoch 174/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 0.4746 - val_accuracy: 0.7532 - val_loss: 0.5125\n",
            "Epoch 175/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7766 - loss: 0.4581 - val_accuracy: 0.7532 - val_loss: 0.5124\n",
            "Epoch 176/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7527 - loss: 0.4790 - val_accuracy: 0.7208 - val_loss: 0.5152\n",
            "Epoch 177/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.4612 - val_accuracy: 0.7208 - val_loss: 0.5199\n",
            "Epoch 178/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.4624 - val_accuracy: 0.7273 - val_loss: 0.5156\n",
            "Epoch 179/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.4547 - val_accuracy: 0.7532 - val_loss: 0.5115\n",
            "Epoch 180/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.4616 - val_accuracy: 0.7273 - val_loss: 0.5168\n",
            "Epoch 181/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.4788 - val_accuracy: 0.7532 - val_loss: 0.5108\n",
            "Epoch 182/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7796 - loss: 0.4525 - val_accuracy: 0.7597 - val_loss: 0.5130\n",
            "Epoch 183/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7689 - loss: 0.4712 - val_accuracy: 0.7532 - val_loss: 0.5112\n",
            "Epoch 184/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7653 - loss: 0.4580 - val_accuracy: 0.7468 - val_loss: 0.5102\n",
            "Epoch 185/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7670 - loss: 0.4793 - val_accuracy: 0.7468 - val_loss: 0.5099\n",
            "Epoch 186/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.4395 - val_accuracy: 0.7273 - val_loss: 0.5148\n",
            "Epoch 187/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7641 - loss: 0.4660 - val_accuracy: 0.7727 - val_loss: 0.5110\n",
            "Epoch 188/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 0.4620 - val_accuracy: 0.7338 - val_loss: 0.5164\n",
            "Epoch 189/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7565 - loss: 0.4622 - val_accuracy: 0.7597 - val_loss: 0.5093\n",
            "Epoch 190/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7696 - loss: 0.4580 - val_accuracy: 0.7468 - val_loss: 0.5137\n",
            "Epoch 191/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7685 - loss: 0.4622 - val_accuracy: 0.7597 - val_loss: 0.5117\n",
            "Epoch 192/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7632 - loss: 0.4526 - val_accuracy: 0.7338 - val_loss: 0.5125\n",
            "Epoch 193/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7692 - loss: 0.4590 - val_accuracy: 0.7727 - val_loss: 0.5116\n",
            "Epoch 194/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.4430 - val_accuracy: 0.7338 - val_loss: 0.5168\n",
            "Epoch 195/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7363 - loss: 0.4881 - val_accuracy: 0.7727 - val_loss: 0.5104\n",
            "Epoch 196/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.4568 - val_accuracy: 0.7468 - val_loss: 0.5083\n",
            "Epoch 197/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7699 - loss: 0.4575 - val_accuracy: 0.7532 - val_loss: 0.5134\n",
            "Epoch 198/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7608 - loss: 0.4837 - val_accuracy: 0.7273 - val_loss: 0.5111\n",
            "Epoch 199/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7576 - loss: 0.4768 - val_accuracy: 0.7662 - val_loss: 0.5083\n",
            "Epoch 200/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.4330 - val_accuracy: 0.7597 - val_loss: 0.5077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "#Clear previous session\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Constructing the Vanilla Model using Sequential\n",
        "#defining the model\n",
        "vanilla_model=Sequential()\n",
        "#Input Layer\n",
        "vanilla_model.add(Dense(64,activation='relu',input_dim=X_train.shape[1]))\n",
        "\n",
        "#First Hidden Layer\n",
        "vanilla_model.add(Dense(32,activation='relu'))\n",
        "\n",
        "#Second Hidden Layer\n",
        "vanilla_model.add(Dense(32,activation='relu'))\n",
        "\n",
        "#Output Layer\n",
        "vanilla_model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "#Compile with a simple SDG\n",
        "vanilla_model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#Vanilla Model summary\n",
        "vanilla_model.summary()\n",
        "\n",
        "# Fit the Model\n",
        "vanilla_model.fit(X_train,y_train,epochs=200,batch_size=32,validation_data=(X_test,y_test))\n",
        "\n",
        "#Save the Model\n",
        "vanilla_model.save('/content/drive/MyDrive/summative_diabetes.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD4DtHXkF9be"
      },
      "source": [
        "Evaluating the Vanilla Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3v2mSK7WGwwS",
        "outputId": "cae25ef7-a88b-4346-c431-f3ea008cc8af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7194 - loss: 0.5204 \n",
            "Test Loss: 0.507681667804718\n",
            ", Test Accuracy: 0.7597402334213257\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        }
      ],
      "source": [
        "#Evaluate the Model\n",
        "test_loss, test_accuracy=vanilla_model.evaluate(X_test,y_test)\n",
        "print(f\"Test Loss: {test_loss}\\n, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "#Make Predictions on the test set\n",
        "y_pred=vanilla_model.predict(X_test)\n",
        "\n",
        "# Convert Probabilities to Binary Predictions\n",
        "y_pred=(y_pred>0.5).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhOgY7vJJD5b"
      },
      "source": [
        "Error Analysis for Vanilla Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DX3SkmHipAcl",
        "outputId": "c306d334-32ad-47aa-fd02-7f65dafc6e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[81 18]\n",
            " [19 36]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "Diabetes_present       0.81      0.82      0.81        99\n",
            " Diabetes_absent       0.67      0.65      0.66        55\n",
            "\n",
            "        accuracy                           0.76       154\n",
            "       macro avg       0.74      0.74      0.74       154\n",
            "    weighted avg       0.76      0.76      0.76       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Confusion Matrix Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Diabetes_present', 'Diabetes_absent'], yticklabels=['Diabetes_present', 'Diabetes_absent'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix of Vanilla Diabetes model')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Diabetes_present', 'Diabetes_absent']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTIMIZED MODEL\n",
        "Using this Optimization Techniques\n",
        "L1 regularization with RMSPOP\n",
        "L1 With Adam Optimizer\n",
        "Drop out\n",
        "\n"
      ],
      "metadata": {
        "id": "g7-BbcgPtr_g"
      }
    },
    {
      "source": [
        "# Clear previous session\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Define the model with L1 Regularization with RMSOP Optimizer and Dropout\n",
        "def create_l1_model(l1_Lambda=0.001, Dropout_rate=0.2):\n",
        "    #initialize the Sequential model\n",
        "    model = Sequential() # Initialize the Sequential model\n",
        "    #Input Layer with l1 Regularization and Dropout\n",
        "    model.add(Dense(64,activation='relu',input_dim=X_train.shape[1],kernel_regularizer=tf.keras.regularizers.l1(l1_Lambda)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    #First Hidden Layer with l1 Regularization and Dropout\n",
        "    model.add(Dense(128,activation='relu',input_shape=(9,1),\n",
        "                  kernel_regularizer= l1(l1_lamba)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Second hidden layer with l1 Regularization Dropout\n",
        "    model.add(Dense(64,activation='relu',kernel_regularizer=tf.keras.regularizers.l1(l1_Lambda)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Output layer with l1 and Dropout\n",
        "    model.add(Dense(32,kernel_regularizer=tf.keras.regularizers.l1(l1_Lambda)))\n",
        "    model.add(Dense(1, kernel_regularizer=tf.keras.regularizers.l1(l1_Lambda), activation='sigmoid'))\n",
        ""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BiSpoMXM-12p"
      },
      "execution_count": 68,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XKUUidnTTWZjGzDCepmEx09AQKFf9YB5",
      "authorship_tag": "ABX9TyOcWconyLGb+G/6dKQ7BjLQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}